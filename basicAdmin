#All notes
#
----START----



#change into a correct namespace (context)
----START----

kubectl config use-context <name_of_cluster>



#how to verify if a node is ready to run normal workloads
----START----

kubectl get nodes //here you can list nodes, but it's not enough
kubectl describe node <nameofnodes_yououtputted> //in "taint" it should have none to be ready
k describe node acgk8s-worker1 | grep -i "taint" //filtered version



#how to verify if a node is ready to run normal workloads
----START----

kubectl get nodes //here you can list nodes, but it's not enough
kubectl describe node <nameofnodes_yououtputted> //in "taint" it should have none to be ready
k describe node acgk8s-worker1 | grep -i "taint" //filtered version using grep

#quickly save smth into txt
----START----
echo "2" > /file_path_wheretowrite

#check logs in specific <namespace> <pod> <container>
----START----
k logs -n  <namespace> <pod> -c <container>


#find out which pod using most cpu in specifx namespace, sorting by cpu filtering by label
----START----
kubectl top pod -n web --sort-by cpu --selector app=auth


/*++++Lab2++++*/

kubectl get services
kubectl edit service 'kubernetes'

#creating a service with specific nodeport enabled on specific deployment in namespace in node
----START----
vi web-frontend-svc.yml

apiVersion: v1
kind: Service
metadata:
  name: web-frontend-svc
  namespace: web
spec:
type:NodePort
  selector: 
    app: web-deployment
  ports:
    -protocol: TCP
    -port: 80
    -nodePort: 30080

kubectl create -f web-frontend.yml


Create a web-frontend-ingress file:

vi web-frontend-ingress.yml
Define an Ingress in the YAML document:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-frontend-ingress
  namespace: web
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-frontend-svc
            port:
              number: 80
Press Esc and enter :wq to save and exit.

Create the Ingress:

kubectl create -f web-frontend-ingress.yml


/*++++Lab4++++*/
#backing up etcd
----START----

//SSH into etcd server
//inside the etcd directory we have the etcd certificates

ETCDCTL_API=3 etcdctl snapshot save /home/cloud_user/etcd_backub.db \
--endpoints=https://etcd1:2379 \
--cacert=/home/..../.crt
--key=/home/.../.key

//in order to backup etcd we must stop etcd and then restore
sudo systemctl stop etcd //stops
sudo rm -rf /var/lib/etcd

//restore
sudo ETCDCTL_API=3 etcdctl snapshot restore /home/cloud_user/etcd_backup.db \
--initial-cluster etcd-restore=https://etcd1:2380 \     //initial cluster value for temp etcd
--initial-advertise-peer-urls etcd-restore=https://etcd1:2380 \ //peer url
--name etcd-restore \
--data-dir /var/lib/etcd

//next I need to make etcd (user and group) own this directory:
sudo chown -R etcd:etcd /var/lib/etcd
sudp systemctl start etcd


sudo ETCDCTL_API=3 etcdctl get cluster.name  \
--initial-cluster etcd-restore=https://etcd1:2380 \     //initial cluster value for temp etcd
--initial-advertise-peer-urls etcd-restore=https://etcd1:2380 \ //peer url
--name etcd-restore \
--data-dir /var/lib/etcd


