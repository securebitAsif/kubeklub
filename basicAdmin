#All notes
#
----START----



#change into a correct namespace (context)
----START----

kubectl config use-context <name_of_cluster>



#how to verify if a node is ready to run normal workloads
----START----

kubectl get nodes //here you can list nodes, but it's not enough
kubectl describe node <nameofnodes_yououtputted> //in "taint" it should have none to be ready
k describe node acgk8s-worker1 | grep -i "taint" //filtered version



#how to verify if a node is ready to run normal workloads
----START----

kubectl get nodes //here you can list nodes, but it's not enough
kubectl describe node <nameofnodes_yououtputted> //in "taint" it should have none to be ready
k describe node acgk8s-worker1 | grep -i "taint" //filtered version using grep

#quickly save smth into txt
----START----
echo "2" > /file_path_wheretowrite

#check logs in specific <namespace> <pod> <container>
----START----
k logs -n  <namespace> <pod> -c <container>


#find out which pod using most cpu in specifx namespace, sorting by cpu filtering by label
----START----
kubectl top pod -n web --sort-by cpu --selector app=auth








/*++++Lab2++++*/

kubectl get services
kubectl edit service 'kubernetes'

#creating a service with specific nodeport enabled on specific deployment in namespace in node
----START----
vi web-frontend-svc.yml

apiVersion: v1
kind: Service
metadata:
  name: web-frontend-svc
  namespace: web
spec:
type:NodePort
  selector: 
    app: web-deployment
  ports:
    -protocol: TCP
    -port: 80
    -nodePort: 30080

kubectl create -f web-frontend.yml


Create a web-frontend-ingress file:

vi web-frontend-ingress.yml
Define an Ingress in the YAML document:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-frontend-ingress
  namespace: web
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-frontend-svc
            port:
              number: 80
Press Esc and enter :wq to save and exit.

Create the Ingress:

kubectl create -f web-frontend-ingress.yml







/*++++Lab4++++*/
#backing up etcd
----START----

//SSH into etcd server
//inside the etcd directory we have the etcd certificates

ETCDCTL_API=3 etcdctl snapshot save /home/cloud_user/etcd_backub.db \
--endpoints=https://etcd1:2379 \
--cacert=/home/..../.crt
--key=/home/.../.key

//in order to backup etcd we must stop etcd and then restore
sudo systemctl stop etcd //stops
sudo rm -rf /var/lib/etcd

//restore
sudo ETCDCTL_API=3 etcdctl snapshot restore /home/cloud_user/etcd_backup.db \
--initial-cluster etcd-restore=https://etcd1:2380 \     //initial cluster value for temp etcd
--initial-advertise-peer-urls etcd-restore=https://etcd1:2380 \ //peer url
--name etcd-restore \
--data-dir /var/lib/etcd

//next I need to make etcd (user and group) own this directory:
sudo chown -R etcd:etcd /var/lib/etcd
sudp systemctl start etcd


sudo ETCDCTL_API=3 etcdctl get cluster.name  \
--initial-cluster etcd-restore=https://etcd1:2380 \     //initial cluster value for temp etcd
--initial-advertise-peer-urls etcd-restore=https://etcd1:2380 \ //peer url
--name etcd-restore \
--data-dir /var/lib/etcd






/*++++Lab5++++*/
//upgrade kubernetes servers
----START----

//upgrade workernodes
kubectl drain k8s-worker1 --ignore-daemonsets --force //run from control plane

//in worker1 we want to perform the upt get install
sudo apt-get install -y --allow-change-held-packages kubeadm=1.27.2-00   //(should match our control node)

/check version
kubeadm version

//upgrade version
kubeadm version 

//kubelet and kubectl are upgraded to the same version:
sudo apt-get install -y --allow-change-held-packages kubelet=1.27.2-00 kubectl=1.27.2-00

//restart kubelet
sudo systemctl daemon-reload
sudo systemctl restart kubelet


//in control plane uncordon worker1
kubectl uncordon k8s-worker1

//confirm it
kubectl get nodes

//same procedure with second one:

kubectl drain k8s-worker2 ignore-daemonsets --force
sudo apt-get install -y --allow-change-help-packages kubeadm=1.27.2-00
kubeadm version
sudo kubeadm upgrade node
sudo apt-get update &&\
sudo apt-get install -y allow-change held-packages kubelet=1.27.2-00 kubectl=1.27.2-00
sudo systemctl daemon-reload
sudo systemctl restart kubelet
kubectl uncordon k8s-worker2
kubectl get nodes






